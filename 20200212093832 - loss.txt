#data #machinelearning A machine learning algorithm is iterative - it
starts with some initial guess an modifies the parameters of the model
until the overall loss (function) produces the minimal possible error.
This means usually until convergence, i. e. that the error from 1 run to
the other changes either very slightly or very slowly.

[815f73eb5c2642786cba64e579389fd3.png]

Loss

Measures how far the predictions of the model are from the real values
(label, target), i. e. how “bad” the model is. To determine this value,
a loss function needs to be defined. In case of linear regression, the
most common function is mean squared error and in the case of logistic
regression it’s log loss

squared loss (error) (L₂ loss)
$$
y...label, \hat{y}...prediction \\
loss_{squared} = (y-\hat{y})^2
$$
* amplifies the influence of outliers because if squaring (unlike L₁
loss)

mean squared error
$$
MSE = \frac{1}{N} \sum_{i=1...N} loss_{squared_i} \\
N...\text{number of observations}
$$

(“Machine Learning Crash Course” n.d.)

“Machine Learning Crash Course.” n.d. Google Developers. Accessed
February 8, 2020.
https://developers.google.com/machine-learning/crash-course.
